{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 7098505,
     "sourceType": "datasetVersion",
     "datasetId": 4091554
    }
   ],
   "dockerImageVersionId": 30733,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session",
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2024-07-11T08:06:14.337045Z",
     "iopub.execute_input": "2024-07-11T08:06:14.337380Z",
     "iopub.status.idle": "2024-07-11T08:06:15.006762Z",
     "shell.execute_reply.started": "2024-07-11T08:06:14.337355Z",
     "shell.execute_reply": "2024-07-11T08:06:15.005750Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import shutil\nimport os\n\n# Define source and destination paths\nsrc_paths = [\n    \"/kaggle/input/chest-diseases-by-medical-imaging-and-cough-sounds/Chest Diseases Using Different Medical Imaging and Cough Sounds/Chest Diseases Dataset/Chest Diseases Dataset/2. Lungs Cancer/CSI\",\n    \"/kaggle/input/chest-diseases-by-medical-imaging-and-cough-sounds/Chest Diseases Using Different Medical Imaging and Cough Sounds/Chest Diseases Dataset/Chest Diseases Dataset/9. Normal/CSI\"\n]\ndst_root = \"/kaggle/working/chest_diseases_dataset\"\n\n# Create destination directory if it does not exist\nos.makedirs(dst_root, exist_ok=True)\n\n# Copy the directories\nfor src in src_paths:\n    dst = os.path.join(dst_root, os.path.basename(os.path.dirname(src)))\n    shutil.copytree(src, dst)\n    print(f\"Copied {src} to {dst}\")\n\nprint(\"All directories copied successfully.\")",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-11T08:06:15.009002Z",
     "iopub.execute_input": "2024-07-11T08:06:15.010025Z",
     "iopub.status.idle": "2024-07-11T08:06:15.488789Z",
     "shell.execute_reply.started": "2024-07-11T08:06:15.009985Z",
     "shell.execute_reply": "2024-07-11T08:06:15.487606Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import os\nimport numpy as np\nimport torchvision.transforms as transforms\nfrom torchvision.utils import save_image\nfrom torch.utils.data import DataLoader\nfrom torchvision.datasets import ImageFolder\nfrom torch.autograd import Variable\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm  # Import tqdm for progress bars\n\n# Define hyperparameters\nn_epochs = 300\nbatch_size = 4\nlr = 0.0002\nb1 = 0.5\nb2 = 0.999\nn_cpu = 4\nlatent_dim = 100\nn_classes = 2\nimg_size = (288, 432)\nchannels = 3\nsample_interval = 100\n\nimg_shape = (channels, *img_size)\n\ncuda = True if torch.cuda.is_available() else False\n\n# Create the necessary directory for saving images and models\nos.makedirs(\"images\", exist_ok=True)\nos.makedirs(\"models\", exist_ok=True)\n\nclass Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n\n        self.label_emb = nn.Embedding(n_classes, n_classes)\n\n        def block(in_feat, out_feat, normalize=True):\n            layers = [nn.Linear(in_feat, out_feat)]\n            if normalize:\n                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n            layers.append(nn.LeakyReLU(0.2, inplace=True))\n            return layers\n\n        self.model = nn.Sequential(\n            *block(latent_dim + n_classes, 128, normalize=False),\n            *block(128, 256),\n            *block(256, 512),\n            *block(512, 1024),\n            nn.Linear(1024, int(np.prod(img_shape))),\n            nn.Tanh()\n        )\n\n    def forward(self, noise, labels):\n        gen_input = torch.cat((self.label_emb(labels), noise), -1)\n        img = self.model(gen_input)\n        img = img.view(img.size(0), *img_shape)\n        return img\n\n\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n\n        self.label_embedding = nn.Embedding(n_classes, n_classes)\n\n        self.model = nn.Sequential(\n            nn.Linear(n_classes + int(np.prod(img_shape)), 512),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Linear(512, 512),\n            nn.Dropout(0.4),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Linear(512, 512),\n            nn.Dropout(0.4),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Linear(512, 1),\n        )\n\n    def forward(self, img, labels):\n        d_in = torch.cat((img.view(img.size(0), -1), self.label_embedding(labels)), -1)\n        validity = self.model(d_in)\n        return validity\n\n\n# Loss functions\nadversarial_loss = torch.nn.MSELoss()\n\n# Initialize generator and discriminator\ngenerator = Generator()\ndiscriminator = Discriminator()\n\nif cuda:\n    generator.cuda()\n    discriminator.cuda()\n    adversarial_loss.cuda()\n\n# Configure data loader\ndata_dir = \"/kaggle/working/chest_diseases_dataset\"\ntransform = transforms.Compose([\n    transforms.Resize(img_size),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5], [0.5])\n])\n\ndataloader = torch.utils.data.DataLoader(\n    ImageFolder(root=data_dir, transform=transform),\n    batch_size=batch_size,\n    shuffle=True,\n    num_workers=n_cpu\n)\n\n# Optimizers\noptimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\noptimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))\n\nFloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\nLongTensor = torch.cuda.LongTensor if cuda else torch.LongTensor\n\n\ndef sample_image(n_row, batches_done):\n    \"\"\"Saves a grid of generated images\"\"\"\n    with torch.no_grad():\n        z = torch.tensor(np.random.normal(0, 1, (n_row ** 2, latent_dim)), dtype=torch.float32, device='cuda' if cuda else 'cpu')\n        labels = np.array([num % n_classes for _ in range(n_row) for num in range(n_row)])\n        labels = torch.tensor(labels, dtype=torch.long, device='cuda' if cuda else 'cpu')\n        gen_imgs = generator(z, labels)\n        save_image(gen_imgs.data, \"images/%d.png\" % batches_done, nrow=n_row, normalize=True)\n\n# Lists to store the loss values\ng_losses = []\nd_losses = []\n\n# Training loop\nfor epoch in range(n_epochs):\n    with tqdm(total=len(dataloader), desc=f\"Epoch {epoch + 1}/{n_epochs}\") as pbar:\n        for i, (imgs, labels) in enumerate(dataloader):\n\n            batch_size = imgs.shape[0]\n\n            valid = torch.tensor(np.ones((batch_size, 1)), dtype=torch.float32, device='cuda' if cuda else 'cpu')\n            fake = torch.tensor(np.zeros((batch_size, 1)), dtype=torch.float32, device='cuda' if cuda else 'cpu')\n\n            real_imgs = imgs.type(FloatTensor)\n            labels = labels.type(LongTensor)\n\n            # Train Generator\n            optimizer_G.zero_grad()\n            z = torch.tensor(np.random.normal(0, 1, (batch_size, latent_dim)), dtype=torch.float32, device='cuda' if cuda else 'cpu')\n            gen_labels = torch.tensor(np.random.randint(0, n_classes, batch_size), dtype=torch.long, device='cuda' if cuda else 'cpu')\n\n            # Ensure gen_labels are within valid range\n            assert gen_labels.max().item() < n_classes, f\"Generated label out of range: {gen_labels.max().item()}\"\n            assert gen_labels.min().item() >= 0, f\"Generated label out of range: {gen_labels.min().item()}\"\n\n            gen_imgs = generator(z, gen_labels)\n            validity = discriminator(gen_imgs, gen_labels)\n            g_loss = adversarial_loss(validity, valid)\n\n            g_loss.backward()\n            optimizer_G.step()\n\n            # Train Discriminator\n            optimizer_D.zero_grad()\n            validity_real = discriminator(real_imgs, labels)\n            d_real_loss = adversarial_loss(validity_real, valid)\n\n            validity_fake = discriminator(gen_imgs.detach(), gen_labels)\n            d_fake_loss = adversarial_loss(validity_fake, fake)\n\n            d_loss = (d_real_loss + d_fake_loss) / 2\n\n            d_loss.backward()\n            optimizer_D.step()\n\n            # Save losses for plotting\n            g_losses.append(g_loss.item())\n            d_losses.append(d_loss.item())\n\n            pbar.set_postfix(D_loss=d_loss.item(), G_loss=g_loss.item())\n            pbar.update(1)\n\n            batches_done = epoch * len(dataloader) + i\n            if batches_done % sample_interval == 0:\n                sample_image(n_row=10, batches_done=batches_done)\n\n    # Save the model every 200 epochs\n    if (epoch + 1) % 50 == 0:\n        torch.save(generator.state_dict(), f\"models/generator_epoch_{epoch+1}.pth\")\n#         torch.save(discriminator.state_dict(), f\"models/discriminator_epoch_{epoch+1}.pth\")\n\n# Plot the loss values\nplt.figure(figsize=(10, 5))\nplt.title(\"Generator and Discriminator Loss During Training\")\nplt.plot(g_losses, label=\"G\")\nplt.plot(d_losses, label=\"D\")\nplt.xlabel(\"iterations\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.savefig(\"loss_plot.png\")\nplt.show()\n\n# Save the final models\ntorch.save(generator.state_dict(), \"models/generator_final.pth\")\n# torch.save(discriminator.state_dict(), \"models/discriminator_final.pth\")",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-11T08:06:15.490344Z",
     "iopub.execute_input": "2024-07-11T08:06:15.490707Z",
     "iopub.status.idle": "2024-07-11T08:19:23.601324Z",
     "shell.execute_reply.started": "2024-07-11T08:06:15.490677Z",
     "shell.execute_reply": "2024-07-11T08:19:23.599918Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torchvision.utils import save_image, make_grid\nimport torch.nn as nn\n\n# Define the same hyperparameters and model architectures used during training\nlatent_dim = 100\nn_classes = 2\nimg_size = (288, 432)\nchannels = 3\nimg_shape = (channels, *img_size)\n\nclass Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n\n        self.label_emb = nn.Embedding(n_classes, n_classes)\n\n        def block(in_feat, out_feat, normalize=True):\n            layers = [nn.Linear(in_feat, out_feat)]\n            if normalize:\n                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n            layers.append(nn.LeakyReLU(0.2, inplace=True))\n            return layers\n\n        self.model = nn.Sequential(\n            *block(latent_dim + n_classes, 128, normalize=False),\n            *block(128, 256),\n            *block(256, 512),\n            *block(512, 1024),\n            nn.Linear(1024, int(np.prod(img_shape))),\n            nn.Tanh()\n        )\n\n    def forward(self, noise, labels):\n        gen_input = torch.cat((self.label_emb(labels), noise), -1)\n        img = self.model(gen_input)\n        img = img.view(img.size(0), *img_shape)\n        return img\n\n# Initialize generator\ngenerator = Generator()\n\n# Load the saved model weights\ngenerator.load_state_dict(torch.load(\"/kaggle/working/models/generator_epoch_250.pth\"))\n\n# Ensure the model is in evaluation mode\ngenerator.eval()\n\n# Generate new images with label 0\ndef generate_images_label_0(num_images, save_path=None):\n    noise = torch.tensor(np.random.normal(0, 1, (num_images, latent_dim)), dtype=torch.float32)\n    labels = torch.zeros(num_images, dtype=torch.long)  # All labels are 0\n    \n    with torch.no_grad():\n        generated_images = generator(noise, labels)\n\n    if save_path:\n        save_image(generated_images.data, save_path, nrow=int(np.sqrt(num_images)), normalize=True)\n\n    return generated_images\n\n# Example usage\nnum_images = 36\ngenerated_images = generate_images_label_0(num_images, save_path=\"generated_images_label_0.png\")\n\n# Display the generated images\ngrid_img = make_grid(generated_images, nrow=int(np.sqrt(num_images)), normalize=True)\nplt.imshow(grid_img.permute(1, 2, 0))\nplt.show()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-11T08:56:57.138280Z",
     "iopub.execute_input": "2024-07-11T08:56:57.139131Z",
     "iopub.status.idle": "2024-07-11T08:57:05.560583Z",
     "shell.execute_reply.started": "2024-07-11T08:56:57.139088Z",
     "shell.execute_reply": "2024-07-11T08:57:05.559651Z"
    },
    "trusted": true
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torchvision.utils import save_image, make_grid\nimport torch.nn as nn\n\n# Define the same hyperparameters and model architectures used during training\nlatent_dim = 100\nn_classes = 2\nimg_size = (288, 432)\nchannels = 3\nimg_shape = (channels, *img_size)\n\nclass Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n\n        self.label_emb = nn.Embedding(n_classes, n_classes)\n\n        def block(in_feat, out_feat, normalize=True):\n            layers = [nn.Linear(in_feat, out_feat)]\n            if normalize:\n                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n            layers.append(nn.LeakyReLU(0.2, inplace=True))\n            return layers\n\n        self.model = nn.Sequential(\n            *block(latent_dim + n_classes, 128, normalize=False),\n            *block(128, 256),\n            *block(256, 512),\n            *block(512, 1024),\n            nn.Linear(1024, int(np.prod(img_shape))),\n            nn.Tanh()\n        )\n\n    def forward(self, noise, labels):\n        gen_input = torch.cat((self.label_emb(labels), noise), -1)\n        img = self.model(gen_input)\n        img = img.view(img.size(0), *img_shape)\n        return img\n\n# Initialize generator\ngenerator = Generator()\n\n# Load the saved model weights\ngenerator.load_state_dict(torch.load(\"/kaggle/working/models/generator_epoch_250.pth\"))\n\n# Ensure the model is in evaluation mode\ngenerator.eval()\n\n# Generate new images with label 1\ndef generate_images_label_1(num_images, save_path=None):\n    noise = torch.tensor(np.random.normal(0, 1, (num_images, latent_dim)), dtype=torch.float32)\n    labels = torch.ones(num_images, dtype=torch.long)  # All labels are 1\n    \n    with torch.no_grad():\n        generated_images = generator(noise, labels)\n\n    if save_path:\n        save_image(generated_images.data, save_path, nrow=int(np.sqrt(num_images)), normalize=True)\n\n    return generated_images\n\n# Example usage\nnum_images = 36\ngenerated_images = generate_images_label_1(num_images, save_path=\"generated_images_label_1.png\")\n\n# Display the generated images\ngrid_img = make_grid(generated_images, nrow=int(np.sqrt(num_images)), normalize=True)\nplt.imshow(grid_img.permute(1, 2, 0))\nplt.show()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-11T08:57:05.562409Z",
     "iopub.execute_input": "2024-07-11T08:57:05.562836Z",
     "iopub.status.idle": "2024-07-11T08:57:13.949482Z",
     "shell.execute_reply.started": "2024-07-11T08:57:05.562805Z",
     "shell.execute_reply": "2024-07-11T08:57:13.948540Z"
    },
    "trusted": true
   },
   "execution_count": 21,
   "outputs": []
  }
 ]
}
